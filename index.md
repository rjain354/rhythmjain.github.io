## Hi there!
<table border="0">
 <tr>
    <td><b style="font-size:30px"></b></td>
    <td><b style="font-size:30px"></b></td>
 </tr>
 <tr>
    <td><img id="profile" align="centre" width="2500" alt="rhythmProfile" src="https://user-images.githubusercontent.com/78115400/151638487-2b039251-bbd4-4155-a3b6-1b3c37c4a165.jpg"></td>
    <td>I am a second year Masters student researcher at <a href="https://music.gatech.edu/master-science-music-technology">Georgia Tech Centre for Music Technology</a> in computational musicology, specializing in music emotion recognition and cross cultural music perception. I have also done extensive work in human subject studies, data analysis, music information retrieval (MIR), digital signal processing, Max/MSP/Jitter, and symbolic music analysis of Hindustani classical music. Throughout the program I have worked on numerous projects some of which are highlighted below. I completed my under graduate studies from BITS Pilani, studying Mathematics and Computer Science. Shortly after I interned at various places including Amazon Development Centre, Goodera and IBM and worked as Software Engineer at Xilinx.</td>
 </tr>
</table>

<p>
<style>
  #profile{
    border-radius: 50%;
  }
  </style>

  </p>

## My Research 
### A Cross-cultural Examination of Raga perception and time-of-day
In Hindustani classical music, there is a historic association between a raga and the time-of-day (prahar) that the raga should be performed.  We wanted to understand if prahar is purely a learned cultural aspect of the performance tradition, or whether it can be perceived. Listeners selected the most appropriate time of day in a forced-alternative task. Based on a pilot study, we chose four maximally- separated time intervals ( morning, afternoon, evening, night) and asked participants to select the time of the day they would most likely want to listen to each given audio clip. We are conducting analyses on the collected data.
## My Projects
### Sur Tarang
#### An interactive bio-feedback music system
<p>
<img align="centre" width="250" alt="Screen Shot 2022-01-28 at 19 00 47" src="https://user-images.githubusercontent.com/78115400/151637279-5af2591c-41aa-4b99-bb5c-c85eb44a932c.png"><img align="centre" width="492" alt="Screen Shot 2022-01-28 at 19 05 52" src="https://user-images.githubusercontent.com/78115400/151637624-ee30e406-d263-4a2b-a15d-da0acaa2de04.png">
</p>

Sur Tarang is an interactive and generative music system enabling musicians to control several parameters of the accompanying instruments without the need to touch or manipulate physical interfaces. Sur Tarang translated body and mind signals (bio signals via EEG) as well as automatic gesture recognition into
the sounds of the accompanying instruments. The sound design was done in Ableton Live and the generative component used dynamic time warping to recognize gestures and mirror the ”Jugalbandi” style of performance prominent in Hindustani classical music. For more details check out the demo(https://www.youtube.com/watch?v=88lU0gK0yoM) and the [github](https://github.com/rjain354/SurTarang) repository.

### Melograph
![Image](https://user-images.githubusercontent.com/78115400/151636271-d8e6794f-9df5-44bd-8b0d-94c9079dc83a.png) <img width="500" alt="Screen Shot 2022-01-28 at 18 43 55" src="https://user-images.githubusercontent.com/78115400/151636285-5e37ea06-171a-4dbd-8b8b-3990a0f6889a.png">

![image](https://user-images.githubusercontent.com/78115400/152262124-167cd5ec-3d3a-4027-b9de-382079915a2a.png)

MeloGraph is a visualization tool to aid musicians with their improvisation techniques. By extracting note-level pitch information from a given audio signal of a monophonic performance, this tool shows the relative note and transition prominence in the user’s performance. We used Harmonic Percussive Source Separation (HPSS) for onset detection, Normalized cross corelation function (NCCF) algorithms for F0 detection and NetworkX and Cytoscape libraries for visualization. For more details check out the [github](https://github.com/nol-alb/melograph_submission) repository.

### Software Synthesizer
We designed a python-based synthesizer that can be run using the command line. The codebase for the project can be found at this [github](https://github.com/rjain354/music6202/tree/main/FinalProject) repository. Taking symbolic music notation (Kern files) as input, the system produces synthesized output files in .wav format, downloaded to the user’s local machine. Synthesis of the signals was done using additive and wave table techniques.

### Others

#### Computational and Cognitive Lab Website
Over summer 2021, I designed a [website](https://ccml.gtcmt.gatech.edu/) for the Computational and Cognitive (CCM) lab at Georgia Tech which contains information about the latest news, team members and publications of the lab. This website allows the CCM lab to reach interested researchers seeking collaborations with the lab.

### Resume
Check out my presence on social media links and my [resume](https://github.com/rjain354/rjain354.github.io/files/7962616/Rhythm_Jain_2022.pdf).


